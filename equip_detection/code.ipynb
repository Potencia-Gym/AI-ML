{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'gym-data'\n",
    "classes = ['Dumbells','Elliptical Machine','Home Machine','Recumbent Bike']\n",
    "temp_train_dir = 'model-data/temp_train_dir'\n",
    "temp_val_dir = 'model-data/temp_val_dir'\n",
    "temp_test_dir = 'model-data/temp_test_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [temp_train_dir, temp_val_dir, temp_test_dir]:\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "        for cls in classes:\n",
    "            os.makedirs(os.path.join(folder, cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    class_dir = os.path.join(dataset_dir,cls)\n",
    "    images = os.listdir(class_dir)\n",
    "    images = [os.path.join(class_dir, img) for img in images]\n",
    "    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    train_images, val_images = train_test_split(train_images, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    for train_img in train_images:\n",
    "        shutil.copy(train_img, os.path.join(temp_train_dir, cls))\n",
    "    for val_img in val_images:\n",
    "        shutil.copy(val_img, os.path.join(temp_val_dir, cls))\n",
    "    for test_img in test_images:\n",
    "        shutil.copy(test_img, os.path.join(temp_test_dir, cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Generator for Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 474 images belonging to 4 classes.\n",
      "Found 161 images belonging to 4 classes.\n",
      "Found 161 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    temp_train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    temp_val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    temp_test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the MobileNetV2 model for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = MobileNetV2(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "# Freezing the layers\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 23s 1s/step - loss: 0.9534 - accuracy: 0.5814 - val_loss: 0.6393 - val_accuracy: 0.7688\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.5021 - accuracy: 0.8394 - val_loss: 0.4358 - val_accuracy: 0.8562\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 19s 1s/step - loss: 0.3534 - accuracy: 0.8959 - val_loss: 0.3635 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2828 - accuracy: 0.9095 - val_loss: 0.3286 - val_accuracy: 0.8687\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 16s 1s/step - loss: 0.2478 - accuracy: 0.9253 - val_loss: 0.3106 - val_accuracy: 0.8813\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.2421 - accuracy: 0.9299 - val_loss: 0.3010 - val_accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.1907 - accuracy: 0.9480 - val_loss: 0.2991 - val_accuracy: 0.8875\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 17s 1s/step - loss: 0.1843 - accuracy: 0.9457 - val_loss: 0.2787 - val_accuracy: 0.8687\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.1956 - accuracy: 0.9397 - val_loss: 0.2831 - val_accuracy: 0.8625\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 15s 1s/step - loss: 0.1480 - accuracy: 0.9593 - val_loss: 0.2656 - val_accuracy: 0.8875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230779b3f90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True # Unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 3/14 [=====>........................] - ETA: 36s - loss: 0.7358 - accuracy: 0.7222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 62s 3s/step - loss: 0.5989 - accuracy: 0.7896 - val_loss: 0.2672 - val_accuracy: 0.8875\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.4563 - accuracy: 0.8462 - val_loss: 0.2835 - val_accuracy: 0.8813\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.4176 - accuracy: 0.8597 - val_loss: 0.2845 - val_accuracy: 0.8813\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 42s 3s/step - loss: 0.3792 - accuracy: 0.8846 - val_loss: 0.2624 - val_accuracy: 0.8875\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 48s 3s/step - loss: 0.3264 - accuracy: 0.9118 - val_loss: 0.2859 - val_accuracy: 0.8875\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 50s 3s/step - loss: 0.3448 - accuracy: 0.8688 - val_loss: 0.2842 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 49s 3s/step - loss: 0.2843 - accuracy: 0.9163 - val_loss: 0.2862 - val_accuracy: 0.9125\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 44s 3s/step - loss: 0.2943 - accuracy: 0.9095 - val_loss: 0.2853 - val_accuracy: 0.9125\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 45s 3s/step - loss: 0.2572 - accuracy: 0.9163 - val_loss: 0.2883 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.2323 - accuracy: 0.9299 - val_loss: 0.2919 - val_accuracy: 0.9125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230081a5c90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-compile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 831ms/step - loss: 0.2588 - accuracy: 0.9187\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yash Phatak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('gym_classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted class: Recumbent Bike with confidence 0.92\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "model = tf.keras.models.load_model('gym_classification_model.h5')\n",
    "\n",
    "# Define class indices (must match the order in your training generator)\n",
    "class_indices = {'Dumbells': 0, 'Elliptical': 1, 'Home Machine': 2, 'Recumbent Bike': 3}\n",
    "class_labels = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "def classify_image(model, img_path):\n",
    "    \"\"\"Classify a new image using the trained model.\"\"\"\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    confidence = np.max(predictions)\n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Path to the new image\n",
    "img_path = 'gym-data/test_image3.jpg'\n",
    "\n",
    "# Classify the new image\n",
    "predicted_class, confidence = classify_image(model, img_path)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Predicted class: {predicted_class} with confidence {confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "Predicted class: Home Machine with confidence 0.95\n",
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"```json\\n{\\n  \\\"name\\\": \\\"Full Body Home Machine Workout\\\",\\n  \\\"description\\\": \\\"This workout utilizes common home exercise equipment for a comprehensive full body session.\\\",\\n  \\\"warm_up\\\": \\\"5 minutes of light cardio, such as jogging in place or jumping jacks, followed by dynamic stretches like arm circles, leg swings, and torso twists.\\\",\\n  \\\"exercises\\\": [\\n    {\\n      \\\"name\\\": \\\"Dumbbell Bench Press\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"8-12\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Chest, Triceps, Front Shoulders\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Dumbbell Rows\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"8-12\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Back, Biceps\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Dumbbell Squats\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"10-15\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Quadriceps, Glutes, Hamstrings\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Dumbbell Lunges\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"10-15 per leg\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Quadriceps, Glutes, Hamstrings\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Dumbbell Overhead Press\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"8-12\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Shoulders\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Dumbbell Bicep Curls\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"10-15\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Biceps\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Dumbbell Triceps Extensions\\\",\\n      \\\"equipment\\\": \\\"Dumbbells\\\",\\n      \\\"reps\\\": \\\"10-15\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Triceps\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Plank\\\",\\n      \\\"equipment\\\": \\\"None\\\",\\n      \\\"reps\\\": \\\"Hold for 30-60 seconds\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Core\\\"\\n    },\\n    {\\n      \\\"name\\\": \\\"Crunches\\\",\\n      \\\"equipment\\\": \\\"None\\\",\\n      \\\"reps\\\": \\\"15-20\\\",\\n      \\\"sets\\\": \\\"3\\\",\\n      \\\"target_muscles\\\": \\\"Abdominals\\\"\\n    }\\n  ],\\n  \\\"cool_down\\\": \\\"5 minutes of static stretches, holding each stretch for 30 seconds.\\\"\\n}\\n``` \\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 48,\n",
      "        \"candidates_token_count\": 651,\n",
      "        \"total_token_count\": 699\n",
      "      }\n",
      "    }),\n",
      ")\n",
      "Invalid JSON data: Expecting ',' delimiter: line 12 column 6 (char 519)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras import models\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "import json\n",
    "import textwrap\n",
    "import google.generativeai as genai \n",
    "import re\n",
    "\n",
    "\n",
    "model = keras.models.load_model('gym_classification_model.h5')\n",
    "\n",
    "class_indices = {'Dumbells': 0, 'Elliptical': 1, 'Home Machine': 2, 'Recumbent Bike': 3}\n",
    "class_labels = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "def classify_image(model, img_path):\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    confidence = np.max(predictions)\n",
    "    return predicted_class, confidence\n",
    "\n",
    "img_path = 'gym-data/test_image4.jpg'\n",
    "\n",
    "predicted_class, confidence = classify_image(model, img_path)\n",
    "print(f\"Predicted class: {predicted_class} with confidence {confidence:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyAcIimOXgOOEMMIcSyUhZ_RoOtKSe38VRY'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "gemini = genai.GenerativeModel('gemini-1.5-flash')\n",
    "prompt = f\"Give a workout plan  (name,description, warm up, reps , target muscles ) for the detected equipment in json documented format: {predicted_class}. Strictly maintain only one  json format. Every field in json is in string datatype.\"\n",
    "response = gemini.generate_content(prompt)\n",
    "# response = response.to_dict()\n",
    "print(response)\n",
    "response = response.to_dict()\n",
    "text = response['candidates'][0]['content']['parts'][0]['text']\n",
    "\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write(text)\n",
    "\n",
    "# Reading the response\n",
    "with open('output.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "pattern = re.compile(r'({.*?})', re.DOTALL)\n",
    "match = pattern.search(content)\n",
    "\n",
    "if match:\n",
    "    json_string = match.group(1)\n",
    "    try:\n",
    "        json_data = json.loads(json_string)\n",
    "        with open('output.json', 'w') as json_file:\n",
    "            json.dump(json_data, json_file, indent=4)\n",
    "        \n",
    "        print(\"JSON data successfully extracted and saved to 'output.json'.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Invalid JSON data:\", e)\n",
    "else:\n",
    "    print(\"No JSON content found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
